{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.cross_validation import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import LogisticRegressionCV          \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data we want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = ['/data/reddit1.csv', \n",
    "         '/data/reddit2.csv',\n",
    "         '/data/reddit3.csv',\n",
    "         '/data/reddit4.csv',\n",
    "         '/data/reddit5.csv',\n",
    "         '/data/reddit6.csv',\n",
    "         '/data/reddit7.csv',\n",
    "         '/data/reddit8.csv',]\n",
    "\n",
    "test =  ['/data/reddit9.csv',\n",
    "         '/data/reddit10.csv']\n",
    "\n",
    "finalDf = pd.DataFrame()\n",
    "finalDf2 = pd.DataFrame()\n",
    "\n",
    "for file in train:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['body', 'created_utc', 'controversiality']]\n",
    "    #adding the controversial \n",
    "    controversial = df[df['controversiality'] == 1].copy().reset_index()\n",
    "    del controversial['index']\n",
    "    finalDf = finalDf.append(controversial,ignore_index = True)\n",
    "    #adding the non-controversial \n",
    "    non_controversial = df[df['controversiality'] == 0].sample(frac=0.03, replace=False).copy().reset_index()\n",
    "    del non_controversial['index']\n",
    "    finalDf = finalDf.append(non_controversial, ignore_index = True)\n",
    "\n",
    "df_train = finalDf\n",
    "\n",
    "for file in test:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['body', 'created_utc', 'controversiality']]\n",
    "    #adding the controversial \n",
    "    controversial = df[df['controversiality'] == 1].copy().reset_index()\n",
    "    del controversial['index']\n",
    "    finalDf2 = finalDf2.append(controversial,ignore_index = True)\n",
    "    #adding the non-controversial \n",
    "    non_controversial = df[df['controversiality'] == 0].sample(frac=0.03, replace=False).copy().reset_index()\n",
    "    del non_controversial['index']\n",
    "    finalDf2 = finalDf2.append(non_controversial, ignore_index = True)\n",
    "\n",
    "df_test = finalDf2\n",
    "\n",
    "del df\n",
    "\n",
    "df_train = df_train.drop('created_utc', axis=1)\n",
    "df_train['body'] = df_train['body'].astype(str)\n",
    "\n",
    "df_test = df_test.drop('created_utc', axis=1)\n",
    "df_test['body'] = df_test['body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = df_train.controversiality\n",
    "y_test = df_test.controversiality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractFeature(vectorizer, selector, x_train, y_train, test):\n",
    "    training = vectorizer.fit_transform(x_train)\n",
    "    test = vectorizer.transform(test)\n",
    "    x_train = selector.fit_transform(training, y_train)\n",
    "    x_test = selector.transform(test)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logisticModel(x_train, y_train, x_test, y_test):\n",
    "    model = LogisticRegressionCV(cv = 5, max_iter=2000, n_jobs=-1)\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_train, y_train)\n",
    "    accuracy_cv = model.score(x_test, y_test)\n",
    "    return accuracy, accuracy_cv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.72189361518731376, 0.65195123573512226)\n"
     ]
    }
   ],
   "source": [
    "#unigram\n",
    "x_train, x_test = extractFeature(TfidfVectorizer(sublinear_tf=True, max_df=0.7, \n",
    "                                                 stop_words='english'),\n",
    "                                 SelectPercentile(score_func=chi2, percentile=50),\n",
    "                                 df_train.body,\n",
    "                                 y_train,\n",
    "                                 df_test.body\n",
    "                                )\n",
    "print(logisticModel(x_train, y_train, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.93535048095179296, 0.60008931880160776)\n"
     ]
    }
   ],
   "source": [
    "#bi-gram\n",
    "x_train, x_test = extractFeature(TfidfVectorizer(sublinear_tf=True, max_df=0.7, \n",
    "                                                 stop_words='english', ngram_range=(2,2)),\n",
    "                                 SelectPercentile(score_func=chi2, percentile=50),\n",
    "                                 df_train.body,\n",
    "                                 y_train,\n",
    "                                 df_test.body\n",
    "                                )\n",
    "print(logisticModel(x_train, y_train, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.70784129639163851, 0.64179359755228471)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = extractFeature(CountVectorizer(analyzer='word', stop_words='english'),\n",
    "                                 SelectPercentile(score_func=chi2, percentile=90),\n",
    "                                 df_train.body,\n",
    "                                 y_train,\n",
    "                                 df_test.body\n",
    "                                )\n",
    "print(logisticModel(x_train, y_train, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mix bigram unigram\n",
    "x_train, x_test = extractFeature(TfidfVectorizer(sublinear_tf=True, max_df=0.7, \n",
    "                                                 stop_words='english', ngram_range=(1,2)),\n",
    "                                 SelectPercentile(score_func=chi2, percentile=90),\n",
    "                                 df_train.body,\n",
    "                                 y_train,\n",
    "                                 df_test.body\n",
    "                                )\n",
    "accu, accu2, model = logisticModel(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to create columns for \n",
    "    1. Time of Day\n",
    "    2. Day of Week\n",
    "    3. Word Count\n",
    "    4. top 500 word for controversial (tfidf value)\n",
    "    5. top 500 word for non-controversial (tfidf value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['body'] = df['body'].astype('str')\n",
    "df['length']=df['body'].str.split(' ').str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct contraversial word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['created_utc']\n",
    "top_n_words = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "controversial = df[df['controversiality'] == 1]\n",
    "comments = controversial['body']\n",
    "vectorizer = TfidfVectorizer(min_df=1, stop_words='english', analyzer='word')\n",
    "X = vectorizer.fit_transform(comments)\n",
    "idf = vectorizer.idf_\n",
    "\n",
    "tfidf_score = dict(zip(vectorizer.get_feature_names(), idf))\n",
    "tfidf_score_sorted = sorted(tfidf_score.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "controversial_words = list( tfidf_score_sorted[:top_n_words][x][0] for x in range(top_n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_controversial = df[df['controversiality'] == 0]\n",
    "comments = non_controversial['body']\n",
    "vectorizer = TfidfVectorizer(min_df=1, stop_words='english', analyzer='word')\n",
    "X = vectorizer.fit_transform(comments)\n",
    "idf = vectorizer.idf_\n",
    "\n",
    "tfidf_score = dict(zip(vectorizer.get_feature_names(), idf))\n",
    "tfidf_score_sorted = sorted(tfidf_score.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "non_controversial_words = list( tfidf_score_sorted[:top_n_words][x][0] for x in range(top_n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words=[]\n",
    "for word in non_controversial_words: \n",
    "    df[word+'count']=0\n",
    "    words.append(word)\n",
    "for word in controversial_words:\n",
    "    df[word+'count']=0\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict for easy lookup\n",
    "ws = {}\n",
    "for w in words:\n",
    "    ws[w] = True\n",
    "\n",
    "import re\n",
    "d = {}\n",
    "for row in df.itertuples():\n",
    "    for word in re.findall(r\"[\\w']+\", row[1].strip().lower()):\n",
    "        if word in ws:\n",
    "            if (word+'count', row[0]) not in d:\n",
    "                d[(word+'count', row[0])] = 0\n",
    "            d[(word+'count', row[0])] += 1    \n",
    "            \n",
    "# add the dict to df            \n",
    "for (w, i) in d:\n",
    "    df.set_value(i, w, d[(w, i)])\n",
    "\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify that sum > 0\n",
    "num = 0\n",
    "sums = []\n",
    "cols_to_drop=[]\n",
    "for col in df.columns:\n",
    "    if col != 'body':\n",
    "        su = sum(df[col])\n",
    "        sums.append(su)\n",
    "        if su == 0:\n",
    "            num += 1\n",
    "            cols_to_drop.append(col)\n",
    "# TODO: Delete cols that have sum 0            \n",
    "print(\"there are %d columns that are empty.\" % num)\n",
    "df = df.drop(cols_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(['controversiality', 'body'], axis = 1)\n",
    "y = df['controversiality']\n",
    "lasso_fit = LassoCV(cv = 10, n_alphas=50, max_iter=100000, normalize=True)\n",
    "lasso_fit.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elastic_fit=ElasticNet(alpha=5,l1_ratio=.5,max_iter=100000,normalize=True)\n",
    "elastic_fit.fit(X,y)\n",
    "elastic_fit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col=[]\n",
    "for i in range(len(lasso_fit.coef_)):\n",
    "    if lasso_fit.coef_[i]!=0:\n",
    "        col.append(i + 2)\n",
    "\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_logistic = df.ix[:, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1=LogisticRegression\n",
    "model1.fit(X_logistic, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(df.ix[df['controversiality']==0])/len(df))\n",
    "print(len(df[df['controversiality'] == 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
