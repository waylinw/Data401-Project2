{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Logistic Regression\n",
    "Our goal for this project was to use logistic regression to predict whether a reddit comment will be 'controversial' or not. We took a variety of a different approaches to solving this issue before settling on a model that we deemed best. Our process went as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Approach:  Word frequencies only\n",
    "Our initial approach was to look solely at word counts. Our first thought was to look at just the most frequent words, but we quickly realized that would be cluttered with common words that didn't tell us anything about the body of the comment itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model constructed using entire dataset.\n",
    "\n",
    "We read in the entire CSV and constructed the model from it, and performed logistic regression to produce a model. However, because of the large non-controversial:controversial ratio, the model selected just predicted all xÌ„ as non-controversial. \n",
    "\n",
    "### Next model used a small subset of the non-controversial data.\n",
    "Changed it to about a 1:1 ratio of controversial to non-controversial, using all of the controversial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: Tf-idf Vectorizer\n",
    "We moved onto the tf-idf vectorizer, and picked the top 500 words from both controversial and non-controversial comments by that metric, and tried to fit a model using these counts. However, this model was generating just predictions of non-controversial for every comment, so we quickly moved on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Up: More TF-IDF Vectorization with Unigrams and Bigrams\n",
    "We then began to work on unigram and bigram approach; looking at single words and double words. Using compressed matrices, we were able to get a far more complete picture of our comment bodies. These models began to yield us results that were far more accurate, and actually netted us accuracy beyond picking all as non-controversial. A combination of the top 90% unigram and bigrams was able to get 96% accuracy on our training data, but the threat of overfitting as we saw worse results in our testing data led to us cutting down the number to top 50,000 unigrams/bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some points on overfitting\n",
    "### how we saw that if we gave it 90% of data, we would get amazing results with the training set, but when we perform a second time validation, we saw the performance dramatically decreased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![functions](functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test](results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test](result2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what we decided to go with, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![finalmodel](finalModel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
