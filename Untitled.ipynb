{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.cross_validation import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import LogisticRegressionCV          \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = ['/data/reddit1.csv',\n",
    "         '/data/reddit2.csv',\n",
    "         '/data/reddit3.csv']\n",
    "\n",
    "test =  ['/data/reddit9.csv']\n",
    "\n",
    "finalDf = pd.DataFrame()\n",
    "finalDf2 = pd.DataFrame()\n",
    "\n",
    "for file in train:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['body', 'created_utc', 'controversiality']]\n",
    "    #adding the controversial \n",
    "    controversial = df[df['controversiality'] == 1].copy().reset_index()\n",
    "    del controversial['index']\n",
    "    finalDf = finalDf.append(controversial,ignore_index = True)\n",
    "    #adding the non-controversial \n",
    "    non_controversial = df[df['controversiality'] == 0].sample(frac=0.03, replace=False).copy().reset_index()\n",
    "    del non_controversial['index']\n",
    "    finalDf = finalDf.append(non_controversial, ignore_index = True)\n",
    "\n",
    "df_train = finalDf\n",
    "\n",
    "for file in test:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['body', 'created_utc', 'controversiality']]\n",
    "    #adding the controversial \n",
    "    controversial = df[df['controversiality'] == 1].copy().reset_index()\n",
    "    del controversial['index']\n",
    "    finalDf2 = finalDf2.append(controversial,ignore_index = True)\n",
    "    #adding the non-controversial \n",
    "    non_controversial = df[df['controversiality'] == 0].copy().reset_index()\n",
    "    del non_controversial['index']\n",
    "    finalDf2 = finalDf2.append(non_controversial, ignore_index = True)\n",
    "\n",
    "df_test = finalDf2\n",
    "\n",
    "del df\n",
    "\n",
    "df_train = df_train.drop('created_utc', axis=1)\n",
    "df_train['body'] = df_train['body'].astype(str)\n",
    "\n",
    "df_test = df_test.drop('created_utc', axis=1)\n",
    "df_test['body'] = df_test['body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = df_train.controversiality\n",
    "y_test = df_test.controversiality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractFeature(vectorizer, selector, x_train, y_train, test):\n",
    "    Vect = vectorizer\n",
    "    Sel = selector\n",
    "    training = Vect.fit_transform(x_train)\n",
    "    test = Vect.transform(test)\n",
    "    x_train = Sel.fit_transform(training, y_train)\n",
    "    x_test = Sel.transform(test)\n",
    "    return x_train, x_test, Vect, Sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticModel(x_train, y_train, x_test, y_test):\n",
    "    model = LogisticRegressionCV(cv = 5, max_iter=2000, n_jobs=-1)\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_train, y_train)\n",
    "    accuracy_cv = model.score(x_test, y_test)\n",
    "    return accuracy, accuracy_cv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, vect, sel = extractFeature(TfidfVectorizer(sublinear_tf=True, max_df=0.7, \n",
    "                                                 stop_words='english', ngram_range=(0,2)),\n",
    "                                 SelectKBest(chi2, k=50000),\n",
    "                                 df_train.body,\n",
    "                                 df_train.controversiality,\n",
    "                                 df_test.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158508, 50000)\n",
      "(158508, 2)\n",
      "(1000000, 50000)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(df_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=2, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegressionCV(cv = 2, max_iter=1000, n_jobs=-1)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting score:  0.829106417342\n",
      "proportion of controversial posts in training set:  0.445573724985\n",
      "validation score:  0.775838\n",
      "proportion of controversial posts in testing set:  0.022174\n"
     ]
    }
   ],
   "source": [
    "print(\"model fitting score: \",  model.score(x_train, y_train))\n",
    "print(\"proportion of controversial posts in training set: \", (sum(y_train) / len(y_train)))\n",
    "print(\"validation score: \" , model.score(x_test, y_test))\n",
    "print(\"proportion of controversial posts in testing set: \", (sum(y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidftop50K.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'tfidftop50K.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidfmixbigram.pkl']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vect, 'tfidfmixbigram.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidfselector.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sel, 'tfidfselector.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = x_test.getrow(0).nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
