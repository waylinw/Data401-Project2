{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.cross_validation import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import LogisticRegressionCV          \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalDf = pd.DataFrame()\n",
    "test = ['/data/reddit5.csv',\n",
    "         '/data/reddit6.csv',\n",
    "         '/data/reddit7.csv']\n",
    "train=['/data/reddit4.csv',\n",
    "       '/data/reddit8.csv',\n",
    "       '/data/reddit9.csv']\n",
    "\n",
    "import csv\n",
    "first = True\n",
    "count = 100000\n",
    "with open('train.csv', 'w', newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for file in train:\n",
    "        with open(file, 'r', newline=\"\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            if first == True:\n",
    "                writer.writerow(next(reader))\n",
    "                first = False\n",
    "            else:\n",
    "                next(reader)\n",
    "            for row in reader:\n",
    "                if count == 0:\n",
    "                    break\n",
    "                if(int(row[20]) == 1):\n",
    "                    writer.writerow(row)\n",
    "                    count-=1\n",
    "                elif np.random.randint(100) < 3:\n",
    "                    writer.writerow(row)\n",
    "                    count-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')#test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non con:  54423\n",
      "con:  45577\n",
      "total:  100000\n"
     ]
    }
   ],
   "source": [
    "print('non con: ', sum(df_train.controversiality == 0))\n",
    "print('con: ', sum(df_train.controversiality == 1))\n",
    "print ('total: ', len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = ['/data/reddit1.csv',\n",
    "         '/data/reddit2.csv',\n",
    "         '/data/reddit3.csv']\n",
    "\n",
    "test =  ['/data/reddit9.csv']\n",
    "\n",
    "finalDf = pd.DataFrame()\n",
    "finalDf2 = pd.DataFrame()\n",
    "\n",
    "for file in train:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['body', 'created_utc', 'controversiality']]\n",
    "    #adding the controversial \n",
    "    controversial = df[df['controversiality'] == 1].copy().reset_index()\n",
    "    del controversial['index']\n",
    "    finalDf = finalDf.append(controversial,ignore_index = True)\n",
    "    #adding the non-controversial \n",
    "    non_controversial = df[df['controversiality'] == 0].sample(frac=0.03, replace=False).copy().reset_index()\n",
    "    del non_controversial['index']\n",
    "    finalDf = finalDf.append(non_controversial, ignore_index = True)\n",
    "\n",
    "df_train = finalDf\n",
    "\n",
    "for file in test:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['body', 'created_utc', 'controversiality']]\n",
    "    #adding the controversial \n",
    "    controversial = df[df['controversiality'] == 1].copy().reset_index()\n",
    "    del controversial['index']\n",
    "    finalDf2 = finalDf2.append(controversial,ignore_index = True)\n",
    "    #adding the non-controversial \n",
    "    non_controversial = df[df['controversiality'] == 0].copy().reset_index()\n",
    "    del non_controversial['index']\n",
    "    finalDf2 = finalDf2.append(non_controversial, ignore_index = True)\n",
    "\n",
    "df_test = finalDf2\n",
    "\n",
    "del df\n",
    "\n",
    "df_train = df_train.drop('created_utc', axis=1)\n",
    "df_train['body'] = df_train['body'].astype(str)\n",
    "\n",
    "df_test = df_test.drop('created_utc', axis=1)\n",
    "df_test['body'] = df_test['body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = df_train.controversiality\n",
    "y_test = df_test.controversiality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Functions to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractFeature(vectorizer, selector, x_train, y_train, test):\n",
    "    Vect = vectorizer\n",
    "    Sel = selector\n",
    "    training = Vect.fit_transform(x_train)\n",
    "    test = Vect.transform(test)\n",
    "    x_train = Sel.fit_transform(training, y_train)\n",
    "    x_test = Sel.transform(test)\n",
    "    return x_train, x_test, Vect, Sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, vect, sel = extractFeature(TfidfVectorizer(sublinear_tf=True, max_df=0.7, \n",
    "                                                 stop_words='english', ngram_range=(0,2)),\n",
    "                                 SelectKBest(chi2, k=50000),\n",
    "                                 df_train.body,\n",
    "                                 df_train.controversiality,\n",
    "                                 df_test.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158508, 50000)\n",
      "(158508, 2)\n",
      "(1000000, 50000)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(df_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance boosting time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intercept = model.intercept_\n",
    "coefs = model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 276 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "    test = vect.transform([row])\n",
    "    test_select = sel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 10.73 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 10.9 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "    test_select.dot(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1593646)\t0.168452161796\n",
      "  (0, 1592773)\t0.103445173079\n",
      "  (0, 1583669)\t0.0916475154945\n",
      "  (0, 1542480)\t0.18414335362\n",
      "  (0, 1539685)\t0.0823188827085\n",
      "  (0, 1507017)\t0.230735495011\n",
      "  (0, 1506974)\t0.195920834222\n",
      "  (0, 1505891)\t0.211799510322\n",
      "  (0, 1504451)\t0.195920834222\n",
      "  (0, 1503260)\t0.091352313345\n",
      "  (0, 1401795)\t0.238613857281\n",
      "  (0, 1371347)\t0.154853167381\n",
      "  (0, 1294815)\t0.117783769614\n",
      "  (0, 1250995)\t0.203799196493\n",
      "  (0, 1098375)\t0.139403130211\n",
      "  (0, 1041150)\t0.128546383787\n",
      "  (0, 1039925)\t0.0671722860906\n",
      "  (0, 1012959)\t0.22080993239\n",
      "  (0, 1010434)\t0.156063758759\n",
      "  (0, 819296)\t0.139169025787\n",
      "  (0, 784188)\t0.16793398623\n",
      "  (0, 783903)\t0.0762264204764\n",
      "  (0, 764015)\t0.202243932093\n",
      "  (0, 762153)\t0.0599032786312\n",
      "  (0, 735658)\t0.200803982168\n",
      "  (0, 622326)\t0.081929766963\n",
      "  (0, 518154)\t0.203799196493\n",
      "  (0, 510552)\t0.209388983481\n",
      "  (0, 510511)\t0.102304256118\n",
      "  (0, 459764)\t0.173185844142\n",
      "  (0, 420195)\t0.105908013495\n",
      "  (0, 418899)\t0.0658706761646\n",
      "  (0, 387227)\t0.225145708022\n",
      "  (0, 387031)\t0.148371335057\n",
      "  (0, 385105)\t0.209388983481\n",
      "  (0, 225473)\t0.138259833867\n",
      "  (0, 181732)\t0.174574322693\n",
      "  (0, 163526)\t0.0875981887669\n",
      "  (0, 73355)\t0.136407915886\n"
     ]
    }
   ],
   "source": [
    "test = vect.transform([df_test.body[0]])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4098)\t0.0875981887669\n",
      "  (0, 4781)\t0.174574322693\n",
      "  (0, 6021)\t0.138259833867\n",
      "  (0, 11302)\t0.0658706761646\n",
      "  (0, 18004)\t0.081929766963\n",
      "  (0, 22494)\t0.0599032786312\n",
      "  (0, 24525)\t0.139169025787\n",
      "  (0, 30880)\t0.156063758759\n",
      "  (0, 31625)\t0.0671722860906\n",
      "  (0, 31726)\t0.128546383787\n",
      "  (0, 33614)\t0.139403130211\n",
      "  (0, 39436)\t0.117783769614\n",
      "  (0, 41518)\t0.154853167381\n",
      "  (0, 45721)\t0.091352313345\n",
      "  (0, 45797)\t0.211799510322\n",
      "  (0, 46752)\t0.0823188827085\n",
      "  (0, 48305)\t0.0916475154945\n",
      "  (0, 48569)\t0.103445173079\n"
     ]
    }
   ],
   "source": [
    "test_select = sel.transform(test)\n",
    "print(test_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping ={}\n",
    "extractedFeatures = sel.get_support(indices=True)\n",
    "for i in range(50000):\n",
    "    mapping[extractedFeatures[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.69 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test = vect.transform([df_test.body[0]])\n",
    "pred=0\n",
    "pred+=intercept\n",
    "for val, idx in tuple(zip(test.todense()[0, test.nonzero()[1]].tolist()[0], test.nonzero()[1])):\n",
    "    real_idx = mapping.get(idx)\n",
    "    if real_idx != None:\n",
    "        pred+=coefs[real_idx] * val\n",
    "\n",
    "predict = (1 / (1 + np.exp(-pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=2, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegressionCV(cv = 2, max_iter=1000, n_jobs=-1)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting score:  0.82838090191\n",
      "proportion of controversial posts in training set:  0.445573724985\n",
      "validation score:  0.775333\n",
      "proportion of controversial posts in testing set:  0.022174\n"
     ]
    }
   ],
   "source": [
    "print(\"model fitting score: \",  model.score(x_train, y_train))\n",
    "print(\"proportion of controversial posts in training set: \", (sum(y_train) / len(y_train)))\n",
    "print(\"validation score: \" , model.score(x_test, y_test))\n",
    "print(\"proportion of controversial posts in testing set: \", (sum(y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidftop50K.pkl']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'tfidftop50K.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidfmixbigram.pkl']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vect, 'tfidfmixbigram.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidfselector.pkl']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sel, 'tfidfselector.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidfselectormapping.pkl']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mapping, 'tfidfselectormapping.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
